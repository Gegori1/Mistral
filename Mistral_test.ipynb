{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q -U bitsandbytes\n",
    "# !pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "# !pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "# !pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "# !pip -q install sentencepiece Xformers einops\n",
    "# !pip -q install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import GenerationConfig, pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import BitsAndBytesConfig\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import GenerationConfig, pipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ehartford/samantha-mistral-7b\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ehartford/samantha-mistral-7b\",\n",
    "                                              load_in_8bit=True,\n",
    "                                              device_map='auto',\n",
    "                                              torch_dtype=torch.float16,\n",
    "                                              low_cpu_mem_usage=True,\n",
    "                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.eos_token_id, tokenizer.pad_token_id\n",
    "tokenizer.pad_token_id = 0\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1536,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import textwrap\n",
    "\n",
    "system_prompt = \"A chat between a curious user and an artificial intelligence assistant. \\nThe assistant gives helpful, detailed, and polite answers to the user's questions.\"\n",
    "\n",
    "addon_prompt = \"Your name is Samantha.\"\n",
    "# USER: What is 4x8?\n",
    "# ASSISTANT:\n",
    "def get_prompt(human_prompt):\n",
    "    # prompt_template=f\"{human_prompt}\"\n",
    "    prompt_template = f\"{addon_prompt}\\n{system_prompt}\\n\\nUSER: {human_prompt} \\nASSISTANT: \"\n",
    "    return prompt_template    \n",
    "\n",
    "print(get_prompt('What is the meaning of life?'))\n",
    "\n",
    "def remove_human_text(text):\n",
    "    return text.split('USER:', 1)[0]\n",
    "\n",
    "def parse_text_after_input(data, input_string):\n",
    "    for item in data:\n",
    "        text = item['generated_text']\n",
    "        input_string_index = text.find(input_string)\n",
    "        if input_string_index != -1:\n",
    "            output_text = text[input_string_index+len(input_string):].strip()\n",
    "            output_text = parse_text(output_text)\n",
    "            wrapped_text = textwrap.fill(output_text, width=100)\n",
    "            print(wrapped_text)\n",
    "\n",
    "def parse_text(data):\n",
    "    for item in data:\n",
    "        text = item['generated_text']\n",
    "        assistant_text_index = text.find('ASSISTANT:')\n",
    "        if assistant_text_index != -1:\n",
    "            assistant_text = text[assistant_text_index+len('ASSISTANT:'):].strip()\n",
    "            assistant_text = remove_human_text(assistant_text)\n",
    "            wrapped_text = textwrap.fill(assistant_text, width=100)\n",
    "            print(wrapped_text)\n",
    "            # return assistant_text\n",
    "\n",
    "data = [{'generated_text': '### Human: What is the capital of England? \\n### Response: The capital city of England is London.'}]\n",
    "parse_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A chat between a curious user and an artificial intelligence assistant. \n",
    "# The assistant gives helpful, detailed, and polite answers to the user's questions.\n",
    "# Your name is Samantha. \n",
    "\n",
    "# USER: What is the meaning of life? \n",
    "# ASSISTANT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "prompt = 'What is your name?'\n",
    "raw_output = pipe(get_prompt(prompt))\n",
    "parse_text(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "prompt = 'What can you help me with?'\n",
    "raw_output = pipe(get_prompt(prompt))\n",
    "parse_text(raw_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "prompt = 'What are the difference between Llamas, Alpacas and Vicunas?'\n",
    "raw_output = pipe(get_prompt(prompt))\n",
    "parse_text(raw_output)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
